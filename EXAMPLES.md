# üìö –ü—Ä–∏–∫–ª–∞–¥–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –ø–æ–∫—Ä–∞—â–µ–Ω–æ–≥–æ pipeline

## üéØ –°—Ü–µ–Ω–∞—Ä—ñ—ó –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è

---

## 1Ô∏è‚É£ –ü–µ—Ä—à–∏–π –∑–∞–ø—É—Å–∫ (–ù–æ–≤–∏–π –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á)

### –ú–µ—Ç–∞: –®–≤–∏–¥–∫–æ –ø–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —á–∏ –≤—Å–µ –ø—Ä–∞—Ü—é—î

```bash
# –ö—Ä–æ–∫ 1: –í—Å—Ç–∞–Ω–æ–≤–∏—Ç–∏ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ
pip install -r requirements.txt

# –ö—Ä–æ–∫ 2: –®–≤–∏–¥–∫–∏–π —Ç–µ—Å—Ç (5-15 —Ö–≤–∏–ª–∏–Ω)
python run_improved_pipeline.py --fast-mode --skip-fetch

# –ö—Ä–æ–∫ 3: –ü–µ—Ä–µ–≥–ª—è–Ω—É—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
python -c "import json; print(json.dumps(json.load(open('outputs/signals.json')), indent=2)[:500])"
```

**–©–æ –≤—ñ–¥–±—É–≤–∞—î—Ç—å—Å—è:**
- ‚úÖ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î —ñ—Å–Ω—É—é—á—ñ –¥–∞–Ω—ñ
- ‚úÖ –¢—Ä–µ–Ω—É—î GRU (—à–≤–∏–¥–∫–∏–π)
- ‚úÖ –ë–µ–∑ augmentation
- ‚úÖ –ë–µ–∑ —ñ—Å—Ç–æ—Ä—ñ—ó
- ‚è±Ô∏è ~5-15 —Ö–≤–∏–ª–∏–Ω

---

## 2Ô∏è‚É£ –ü—Ä–æ–¥–∞–∫—à–Ω —Ä–µ–∂–∏–º (–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ —è–∫—ñ—Å—Ç—å)

### –ú–µ—Ç–∞: –ù–∞—Ç—Ä–µ–Ω—É–≤–∞—Ç–∏ –Ω–∞–π–∫—Ä–∞—â—ñ –º–æ–¥–µ–ª—ñ

```bash
# –ü–æ–≤–Ω–∏–π pipeline –∑ —É—Å—ñ–º–∞ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è–º–∏
python run_improved_pipeline.py \
    --model-type ensemble \
    --meta-ensemble \
    --cv-folds 5 \
    --history-days 365

# –ê–±–æ –ø—Ä–æ—Å—Ç–æ
full_improved_pipeline.bat  # Windows
```

**–©–æ –≤—ñ–¥–±—É–≤–∞—î—Ç—å—Å—è:**
- ‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î —Å–≤—ñ–∂—ñ –¥–∞–Ω—ñ –∑ MT5
- ‚úÖ 45+ features
- ‚úÖ –¢—Ä–µ–Ω—É—î LSTM + GRU + Attention
- ‚úÖ Data augmentation (3x data)
- ‚úÖ Walk-forward validation
- ‚úÖ LightGBM + XGBoost ensemble
- ‚úÖ 5-fold cross-validation
- ‚úÖ 365 –¥–Ω—ñ–≤ —ñ—Å—Ç–æ—Ä—ñ—ó
- ‚úÖ –§—ñ–Ω–∞–Ω—Å–æ–≤—ñ –º–µ—Ç—Ä–∏–∫–∏
- ‚è±Ô∏è ~2-4+ –≥–æ–¥–∏–Ω–∏

---

## 3Ô∏è‚É£ –î–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä

### –ú–µ—Ç–∞: –ü–æ—Ä—ñ–≤–Ω—è—Ç–∏ —Ä—ñ–∑–Ω—ñ –º–æ–¥–µ–ª—ñ

```bash
# –¢—Ä–µ–Ω—É–≤–∞—Ç–∏ LSTM
python scripts/train_lstm.py --config config.yaml --model-type lstm
# –†–µ–∑—É–ª—å—Ç–∞—Ç: models/*_lstm.h5

# –¢—Ä–µ–Ω—É–≤–∞—Ç–∏ GRU
python scripts/train_lstm.py --config config.yaml --model-type gru
# –†–µ–∑—É–ª—å—Ç–∞—Ç: models/*_gru.h5

# –¢—Ä–µ–Ω—É–≤–∞—Ç–∏ Attention
python scripts/train_lstm.py --config config.yaml --model-type attention
# –†–µ–∑—É–ª—å—Ç–∞—Ç: models/*_attention.h5

# –ü–æ—Ä—ñ–≤–Ω—è—Ç–∏ –∑–∞ —ñ—Å—Ç–æ—Ä—ñ—î—é –Ω–∞–≤—á–∞–Ω–Ω—è
python -c "
import json, glob
for f in glob.glob('models/*_history.json'):
    with open(f) as fp:
        h = json.load(fp)
        print(f'{f}: val_loss={h[\"val_loss\"][-1]:.4f}, val_accuracy={h[\"val_accuracy\"][-1]:.4f}')
"
```

---

## 4Ô∏è‚É£ –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è —à–≤–∏–¥–∫–æ—Å—Ç—ñ

### –ú–µ—Ç–∞: –®–≤–∏–¥—à–µ –Ω–∞–≤—á–∞–Ω–Ω—è –¥–ª—è –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ñ–≤

```bash
# –í–∞—Ä—ñ–∞–Ω—Ç 1: GRU –±–µ–∑ augmentation
python run_improved_pipeline.py \
    --model-type gru \
    --no-augment \
    --skip-history

# –í–∞—Ä—ñ–∞–Ω—Ç 2: LSTM –∞–ª–µ –±–µ–∑ —ñ—Å—Ç–æ—Ä—ñ—ó
python run_improved_pipeline.py \
    --model-type lstm \
    --skip-history

# –í–∞—Ä—ñ–∞–Ω—Ç 3: Fast mode
python run_improved_pipeline.py --fast-mode
```

**–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è —à–≤–∏–¥–∫–æ—Å—Ç—ñ:**
- Full mode: ~3-4 –≥–æ–¥–∏–Ω–∏
- Skip history: ~30-60 —Ö–≤–∏–ª–∏–Ω
- No augment: ~20-40 —Ö–≤–∏–ª–∏–Ω
- GRU: -30% —á–∞—Å—É –≤—ñ–¥ LSTM
- Fast mode: ~5-15 —Ö–≤–∏–ª–∏–Ω

---

## 5Ô∏è‚É£ –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è Meta-–º–æ–¥–µ–ª—ñ

### –ú–µ—Ç–∞: –ï–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏ –∑ meta-learning

```bash
# –ë–∞–∑–æ–≤–∞ LightGBM
python train_meta_model.py --dataset meta_dataset.csv

# Ensemble (LightGBM + XGBoost)
python train_meta_model.py --dataset meta_dataset.csv --ensemble

# –ó cross-validation
python train_meta_model.py --dataset meta_dataset.csv --cv-folds 5

# –í—Å–µ —Ä–∞–∑–æ–º
python train_meta_model.py --dataset meta_dataset.csv --ensemble --cv-folds 5
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç–∏:**
```
models/
‚îú‚îÄ‚îÄ meta_model_EUR.joblib
‚îú‚îÄ‚îÄ meta_model_GBP.joblib
‚îú‚îÄ‚îÄ meta_model_JPY.joblib
‚îú‚îÄ‚îÄ meta_model_CHF.joblib
‚îú‚îÄ‚îÄ meta_model_AUD.joblib
‚îú‚îÄ‚îÄ meta_model_CAD.joblib
‚îî‚îÄ‚îÄ meta_model_NZD.joblib
```

---

## 6Ô∏è‚É£ Backtest —Ç–∞ Evaluation

### –ú–µ—Ç–∞: –û—Ü—ñ–Ω–∏—Ç–∏ —Ñ—ñ–Ω–∞–Ω—Å–æ–≤—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏

```bash
# –ë–∞–∑–æ–≤–∏–π backtest
python evaluate_backtest.py --history-dir outputs/history

# –ó –∫–∞—Å—Ç–æ–º–Ω–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
python evaluate_backtest.py \
    --history-dir outputs/history \
    --initial-balance 50000 \
    --risk-per-trade 0.01

# –ü–µ—Ä–µ–≥–ª—è–Ω—É—Ç–∏ –∑–≤—ñ—Ç
cat outputs/backtest_report.json
```

**–ü—Ä–∏–∫–ª–∞–¥ –≤–∏–≤–æ–¥—É:**
```
============================================================
BACKTEST RESULTS
============================================================
Initial Balance:    $10,000.00
Final Balance:      $15,234.56
Total Return:       +52.35%
Total Trades:       245
Win Rate:           58.37%

PERFORMANCE METRICS
------------------------------------------------------------
Sharpe Ratio:       1.834
Sortino Ratio:      2.156
Max Drawdown:       18.23%
Calmar Ratio:       2.873
Profit Factor:      1.982
Expectancy:         $21.36
Risk/Reward Ratio:  1.753
============================================================
```

---

## 7Ô∏è‚É£ –ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ –Ω–∞–≤—á–∞–Ω–Ω—è

### –ú–µ—Ç–∞: –í—ñ–¥—Å—Ç–µ–∂—É–≤–∞—Ç–∏ –ø—Ä–æ–≥—Ä–µ—Å –ø—ñ–¥ —á–∞—Å –Ω–∞–≤—á–∞–Ω–Ω—è

```bash
# Terminal 1: –ó–∞–ø—É—Å—Ç–∏—Ç–∏ –Ω–∞–≤—á–∞–Ω–Ω—è
python scripts/train_lstm.py --config config.yaml --ensemble

# Terminal 2: –ú–æ–Ω—ñ—Ç–æ—Ä–∏—Ç–∏ log —Ñ–∞–π–ª–∏ (—è–∫—â–æ —î)
# –ê–±–æ –ø–µ—Ä–µ–≥–ª—è–Ω—É—Ç–∏ —ñ—Å—Ç–æ—Ä—ñ—é –ø—ñ—Å–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è
python -c "
import json, matplotlib.pyplot as plt

with open('models/EURUSD_D1_lstm_history.json') as f:
    h = json.load(f)

plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(h['loss'], label='Train Loss')
plt.plot(h['val_loss'], label='Val Loss')
plt.legend()
plt.title('Loss')

plt.subplot(1, 2, 2)
plt.plot(h['accuracy'], label='Train Acc')
plt.plot(h['val_accuracy'], label='Val Acc')
plt.legend()
plt.title('Accuracy')

plt.savefig('training_curves.png')
print('Saved to training_curves.png')
"
```

---

## 8Ô∏è‚É£ –Ü–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–µ –Ω–∞–≤—á–∞–Ω–Ω—è

### –ú–µ—Ç–∞: –î–æ–¥–∞—Ç–∏ –Ω–æ–≤—ñ –¥–∞–Ω—ñ –±–µ–∑ –ø–æ–≤–Ω–æ–≥–æ –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è

```bash
# –ö—Ä–æ–∫ 1: –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –Ω–æ–≤—ñ –¥–∞–Ω—ñ
python scripts/fetch_mt5.py --config config.yaml

# –ö—Ä–æ–∫ 2: –û–Ω–æ–≤–∏—Ç–∏ dataset
python scripts/make_dataset.py --config config.yaml --walk-forward

# –ö—Ä–æ–∫ 3: –ü–µ—Ä–µ—Ç—Ä–µ–Ω—É–≤–∞—Ç–∏ —Ç—ñ–ª—å–∫–∏ –æ–¥–Ω—É –º–æ–¥–µ–ª—å
python scripts/train_lstm.py --config config.yaml --model-type lstm

# –ö—Ä–æ–∫ 4: –û–Ω–æ–≤–∏—Ç–∏ —Å–∏–≥–Ω–∞–ª–∏
python scripts/infer_signals.py --config config.yaml
```

---

## 9Ô∏è‚É£ Debugging —Ç–∞ Troubleshooting

### –ú–µ—Ç–∞: –ó–Ω–∞–π—Ç–∏ —Ç–∞ –≤–∏–ø—Ä–∞–≤–∏—Ç–∏ –ø—Ä–æ–±–ª–µ–º–∏

```bash
# –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –¥–∞–Ω—ñ
python -c "
import pandas as pd
import glob

for f in glob.glob('data/*_D1.csv'):
    df = pd.read_csv(f)
    print(f'{f}: {len(df)} rows, {df.columns.tolist()[:5]}...')
"

# –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –º–æ–¥–µ–ª—ñ
python -c "
import glob, os

for f in glob.glob('models/*.h5'):
    size = os.path.getsize(f) / 1024 / 1024
    print(f'{f}: {size:.2f} MB')
"

# –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ features
python scripts/make_dataset.py --config config.yaml --walk-forward
# –ü–æ–¥–∏–≤–∏—Ç–∏—Å—å –Ω–∞ _meta.json —Ñ–∞–π–ª–∏
python -c "
import json
with open('data/EURUSD_D1_meta.json') as f:
    meta = json.load(f)
    print(f'Features ({len(meta[\"features\"])}): {meta[\"features\"][:10]}...')
"
```

---

## üîü Production Deployment

### –ú–µ—Ç–∞: –ù–∞–ª–∞—à—Ç—É–≤–∞—Ç–∏ –¥–ª—è –ø–æ—Å—Ç—ñ–π–Ω–æ—ó —Ä–æ–±–æ—Ç–∏

```bash
# Windows Task Scheduler
# –°—Ç–≤–æ—Ä–∏—Ç–∏ task, —â–æ –∑–∞–ø—É—Å–∫–∞—î –∫–æ–∂–µ–Ω –¥–µ–Ω—å –æ 00:00:

# full_retrain.bat:
@echo off
cd D:\LLM\LSTMC
call .venv\Scripts\activate
python run_improved_pipeline.py --skip-history >> logs/daily.log 2>&1

# –ê–±–æ —Ç—ñ–ª—å–∫–∏ inference –±–µ–∑ retraining:
# daily_signals.bat:
@echo off
cd D:\LLM\LSTMC
call .venv\Scripts\activate
python scripts/fetch_mt5.py --config config.yaml
python scripts/infer_signals.py --config config.yaml
python infer_meta_signals.py --config config.yaml
```

---

## üé® –ö–∞—Å—Ç–æ–º—ñ–∑–∞—Ü—ñ—è

### –ü—Ä–∏–∫–ª–∞–¥ 1: –¢—ñ–ª—å–∫–∏ –ø–µ–≤–Ω—ñ —Å–∏–º–≤–æ–ª–∏

```python
# custom_config.yaml
symbols:
  - EURUSD
  - GBPUSD
timeframes:
  H1:
    years: 10
    seq_len: 96
    horizon: 6
```

```bash
python run_improved_pipeline.py --config custom_config.yaml
```

### –ü—Ä–∏–∫–ª–∞–¥ 2: –í–ª–∞—Å–Ω—ñ hyperparameters

–í—ñ–¥—Ä–µ–¥–∞–≥—É–π—Ç–µ `scripts/train_lstm.py`:
```python
# –ó–Ω–∞–π—Ç–∏ build_lstm_model() —Ç–∞ –∑–º—ñ–Ω–∏—Ç–∏:
layers.LSTM(256, ...)  # –ë—É–ª–æ 128
layers.Dropout(0.4)     # –ë—É–ª–æ 0.3
```

### –ü—Ä–∏–∫–ª–∞–¥ 3: –î–æ–¥–∞—Ç–∏ –Ω–æ–≤–∏–π —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä

–í—ñ–¥—Ä–µ–¥–∞–≥—É–π—Ç–µ `scripts/utils.py`:
```python
def make_features(df):
    # ... —ñ—Å–Ω—É—é—á–∏–π –∫–æ–¥ ...

    # –î–æ–¥–∞—Ç–∏ —Å–≤—ñ–π —ñ–Ω–¥–∏–∫–∞—Ç–æ—Ä
    out["MyIndicator"] = your_calculation(out["Close"])

    return out.dropna().reset_index(drop=True)
```

---

## üìä Dashboard —Ç–∞ Visualization

```bash
# –ó–∞–ø—É—Å—Ç–∏—Ç–∏ web dashboard
codex run web
# –∞–±–æ
uvicorn scripts.web_server:app --host 0.0.0.0 --port 8000

# –í—ñ–¥–∫—Ä–∏—Ç–∏ –≤ –±—Ä–∞—É–∑–µ—Ä—ñ
# http://127.0.0.1:8000

# API endpoints:
curl http://127.0.0.1:8000/api/signals
curl http://127.0.0.1:8000/api/prices
```

---

## üí° Pro Tips

### 1. –ü–∞—Ä–∞–ª–µ–ª—å–Ω–µ –Ω–∞–≤—á–∞–Ω–Ω—è —Ä—ñ–∑–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π

```bash
# Terminal 1
python scripts/train_lstm.py --config config.yaml --model-type lstm

# Terminal 2
python scripts/train_lstm.py --config config.yaml --model-type gru

# Terminal 3
python scripts/train_lstm.py --config config.yaml --model-type attention
```

### 2. Automatic retraining script

```bash
# auto_retrain.sh
#!/bin/bash
while true; do
    echo "[$(date)] Starting retraining..."
    python run_improved_pipeline.py --skip-history
    echo "[$(date)] Retraining complete. Sleeping 24h..."
    sleep 86400
done
```

### 3. Email notifications (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ)

```python
# –î–æ–¥–∞—Ç–∏ –≤ –∫—ñ–Ω–µ—Ü—å run_improved_pipeline.py
import smtplib
from email.message import EmailMessage

def send_notification(subject, body):
    msg = EmailMessage()
    msg['Subject'] = subject
    msg['From'] = 'your@email.com'
    msg['To'] = 'recipient@email.com'
    msg.set_content(body)

    with smtplib.SMTP('smtp.gmail.com', 587) as smtp:
        smtp.starttls()
        smtp.login('your@email.com', 'password')
        smtp.send_message(msg)

# –í –∫—ñ–Ω—Ü—ñ main():
send_notification('Pipeline Complete', f'Success: {success_count}/{total_steps}')
```

---

## üÜò –ß–∞—Å—Ç—ñ –ø—Ä–æ–±–ª–µ–º–∏

### –ü—Ä–æ–±–ª–µ–º–∞: Out of Memory

```bash
# –†—ñ—à–µ–Ω–Ω—è: –ó–º–µ–Ω—à–∏—Ç–∏ batch size –∞–±–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ –º–µ–Ω—à–µ timeframes
python scripts/train_lstm.py --config config.yaml --model-type gru --no-augment
```

### –ü—Ä–æ–±–ª–µ–º–∞: MT5 connection failed

```bash
# –†—ñ—à–µ–Ω–Ω—è: –ü–µ—Ä–µ–∫–æ–Ω–∞–π—Ç–µ—Å—å —â–æ MT5 –∑–∞–ø—É—â–µ–Ω–∏–π
# –ê–±–æ –ø—Ä–æ–ø—É—Å—Ç—ñ—Ç—å fetch
python run_improved_pipeline.py --skip-fetch
```

### –ü—Ä–æ–±–ª–µ–º–∞: Training too slow

```bash
# –†—ñ—à–µ–Ω–Ω—è: –í–∏–∫–æ—Ä–∏—Å—Ç–∞–π—Ç–µ fast mode –∞–±–æ GRU
python run_improved_pipeline.py --fast-mode
```

---

–£—Å–ø—ñ—à–Ω–æ–≥–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è! üöÄüìà
